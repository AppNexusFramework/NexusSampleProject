name: Build and Release Binary

on:
  push:
    branches:
      - main
  workflow_dispatch:
    inputs:
      version_bump:
        description: 'Version bump type'
        required: true
        type: choice
        options:
          - patch
          - minor
          - major
        default: 'patch'
      component_name:
        description: 'Nexus component name (e.g., NexusSkyTransform, nexus_kube)'
        required: false
        type: string
        default: ''
      binary_base_name:
        description: 'Base name for binary output (e.g., nexus-sky, nexus-kube)'
        required: false
        type: string
        default: ''
      python_version:
        description: 'Python version to use'
        required: false
        type: string
        default: ''
      enable_linux:
        description: 'Build Linux binary'
        required: false
        type: boolean
        default: true
      enable_windows:
        description: 'Build Windows binary'
        required: false
        type: boolean
        default: true
      enable_macos:
        description: 'Build macOS binary'
        required: false
        type: boolean
        default: true

env:
  CONFIG_FILE: 'app/app.json'

jobs:
  setup:
    name: Setup Build Environment
    runs-on: ubuntu-latest
    outputs:
      version_bump: ${{ steps.config.outputs.version_bump }}
      component_name: ${{ steps.config.outputs.component_name }}
      binary_name: ${{ steps.config.outputs.binary_name }}
      python_version: ${{ steps.config.outputs.python_version }}
      build_linux: ${{ steps.config.outputs.build_linux }}
      build_windows: ${{ steps.config.outputs.build_windows }}
      build_macos: ${{ steps.config.outputs.build_macos }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install jq
        run: |
          sudo apt-get update
          sudo apt-get install -y jq

      - name: Read build configuration
        id: config
        run: |
          CONFIG_FILE="${{ env.CONFIG_FILE }}"
          
          # Check if manual trigger has values
          MANUAL_COMPONENT="${{ github.event.inputs.component_name }}"
          MANUAL_BINARY="${{ github.event.inputs.binary_base_name }}"
          MANUAL_PYTHON="${{ github.event.inputs.python_version }}"
          
          # If manually triggered with values, use them
          if [ "${{ github.event_name }}" == "workflow_dispatch" ] && [ -n "$MANUAL_COMPONENT" ]; then
            echo "Using manual trigger values"
            VERSION_BUMP="${{ github.event.inputs.version_bump }}"
            COMPONENT_NAME="$MANUAL_COMPONENT"
            BINARY_NAME="$MANUAL_BINARY"
            PYTHON_VERSION="${MANUAL_PYTHON:-3.11}"
            BUILD_LINUX="${{ github.event.inputs.enable_linux }}"
            BUILD_WINDOWS="${{ github.event.inputs.enable_windows }}"
            BUILD_MACOS="${{ github.event.inputs.enable_macos }}"
          else
            # Read from config file
            echo "Reading from config file: $CONFIG_FILE"
            
            if [ ! -f "$CONFIG_FILE" ]; then
              echo "Error: Config file not found: $CONFIG_FILE"
              exit 1
            fi
            
            VERSION_BUMP=$(jq -r '.version_bump // "patch"' "$CONFIG_FILE")
            COMPONENT_NAME=$(jq -r '.component_name' "$CONFIG_FILE")
            BINARY_NAME=$(jq -r '.binary_base_name' "$CONFIG_FILE")
            PYTHON_VERSION=$(jq -r '.python_version // "3.11"' "$CONFIG_FILE")
            BUILD_LINUX=$(jq -r '.build_targets.linux // true' "$CONFIG_FILE")
            BUILD_WINDOWS=$(jq -r '.build_targets.windows // true' "$CONFIG_FILE")
            BUILD_MACOS=$(jq -r '.build_targets.macos // true' "$CONFIG_FILE")
          fi
          
          # Validate required fields
          if [ -z "$COMPONENT_NAME" ] || [ "$COMPONENT_NAME" == "null" ]; then
            echo "Error: component_name is required"
            exit 1
          fi
          
          if [ -z "$BINARY_NAME" ] || [ "$BINARY_NAME" == "null" ]; then
            echo "Error: binary_base_name is required"
            exit 1
          fi
          
          # Output configuration
          echo "version_bump=$VERSION_BUMP" >> $GITHUB_OUTPUT
          echo "component_name=$COMPONENT_NAME" >> $GITHUB_OUTPUT
          echo "binary_name=$BINARY_NAME" >> $GITHUB_OUTPUT
          echo "python_version=$PYTHON_VERSION" >> $GITHUB_OUTPUT
          echo "build_linux=$BUILD_LINUX" >> $GITHUB_OUTPUT
          echo "build_windows=$BUILD_WINDOWS" >> $GITHUB_OUTPUT
          echo "build_macos=$BUILD_MACOS" >> $GITHUB_OUTPUT
          
          # Display configuration
          echo "Configuration loaded:"
          echo "  Component: $COMPONENT_NAME"
          echo "  Binary: $BINARY_NAME"
          echo "  Python: $PYTHON_VERSION"
          echo "  Version Bump: $VERSION_BUMP"
          echo "  Build Linux: $BUILD_LINUX"
          echo "  Build Windows: $BUILD_WINDOWS"
          echo "  Build macOS: $BUILD_MACOS"

  version:
    name: Determine Version
    needs: setup
    runs-on: ubuntu-latest
    outputs:
      new_version: ${{ steps.bump_version.outputs.new_version }}
      version_bump: ${{ steps.set_bump.outputs.version_bump }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set version bump type
        id: set_bump
        run: |
          # Check if manually triggered
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "version_bump=${{ github.event.inputs.version_bump }}" >> $GITHUB_OUTPUT
          else
            # Use version from config or auto-detect from commit
            VERSION_BUMP="${{ needs.setup.outputs.version_bump }}"
            
            if [ "$VERSION_BUMP" == "auto" ] || [ -z "$VERSION_BUMP" ]; then
              # Auto-detect from commit message
              COMMIT_MSG=$(git log -1 --pretty=%B)
              if [[ "$COMMIT_MSG" =~ \[major\] ]] || [[ "$COMMIT_MSG" =~ BREAKING\ CHANGE ]]; then
                VERSION_BUMP="major"
              elif [[ "$COMMIT_MSG" =~ \[minor\] ]] || [[ "$COMMIT_MSG" =~ ^feat ]]; then
                VERSION_BUMP="minor"
              else
                VERSION_BUMP="patch"
              fi
            fi
            
            echo "version_bump=$VERSION_BUMP" >> $GITHUB_OUTPUT
          fi
          
          echo "Version bump type: $(cat $GITHUB_OUTPUT | grep version_bump | cut -d= -f2)"
      
      - name: Get latest tag
        id: get_latest_tag
        run: |
          COMPONENT="${{ needs.setup.outputs.component_name }}"
          LATEST_TAG=$(git tag -l "${COMPONENT}-v*" --sort=-v:refname | head -n 1)
          
          if [ -z "$LATEST_TAG" ]; then
            LATEST_TAG="${COMPONENT}-v0.0.0"
          fi
          
          echo "latest_tag=$LATEST_TAG" >> $GITHUB_OUTPUT
          echo "Latest tag: $LATEST_TAG"
      
      - name: Bump version
        id: bump_version
        run: |
          LATEST_TAG="${{ steps.get_latest_tag.outputs.latest_tag }}"
          VERSION_BUMP="${{ steps.set_bump.outputs.version_bump }}"
          COMPONENT="${{ needs.setup.outputs.component_name }}"
          
          echo "Latest tag: $LATEST_TAG"
          echo "Component: $COMPONENT"
          echo "Version bump: $VERSION_BUMP"
          
          # Remove component prefix and 'v' prefix
          VERSION="${LATEST_TAG#${COMPONENT}-v}"
          
          echo "Extracted version: $VERSION"
          
          # Split version into components using parameter expansion
          MAJOR="${VERSION%%.*}"
          TEMP="${VERSION#*.}"
          MINOR="${TEMP%%.*}"
          PATCH="${TEMP#*.}"
          
          # Default to 0 if empty
          MAJOR="${MAJOR:-0}"
          MINOR="${MINOR:-0}"
          PATCH="${PATCH:-0}"
          
          echo "Current version: $MAJOR.$MINOR.$PATCH"
          
          # Bump version based on type
          case "$VERSION_BUMP" in
            major)
              MAJOR=$((MAJOR + 1))
              MINOR=0
              PATCH=0
              ;;
            minor)
              MINOR=$((MINOR + 1))
              PATCH=0
              ;;
            patch)
              PATCH=$((PATCH + 1))
              ;;
            *)
              echo "Unknown version bump type: $VERSION_BUMP"
              exit 1
              ;;
          esac
          
          NEW_VERSION="${COMPONENT}-v${MAJOR}.${MINOR}.${PATCH}"
          echo "new_version=$NEW_VERSION" >> $GITHUB_OUTPUT
          echo "New version: $NEW_VERSION (bump type: $VERSION_BUMP)"

  test:
    name: Run Unit Tests
    needs: [setup, version]
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ needs.setup.outputs.python_version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt || echo "No requirements.txt found"
          pip install pytest || echo "pytest not required"

      - name: Run tests (if available)
        run: |
          if [ -d "tests" ]; then
            echo "Running tests from 'tests/'..."
            pytest tests/ --maxfail=3 --disable-warnings -q || echo "Some tests failed, continuing..."
          elif [ -d "test" ]; then
            echo "Running tests from 'test/'..."
            pytest test/ --maxfail=3 --disable-warnings -q || echo "Some tests failed, continuing..."
          else
            echo "No test directory found, skipping tests."
          fi
        shell: bash

  build:
    name: Build Binary Modules
    needs: [setup, version, test]
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            platform: linux
            extension: .so
            artifact_name: linux-binary
          - os: windows-latest
            platform: windows
            extension: .pyd
            artifact_name: windows-binary
          - os: macos-latest
            platform: macos
            extension: .so
            artifact_name: macos-binary
    
    steps:
      - name: Check if platform is enabled
        id: check_enabled
        shell: bash
        run: |
          ENABLED="true"
          
          if [ "${{ matrix.platform }}" == "linux" ] && [ "${{ needs.setup.outputs.build_linux }}" != "true" ]; then
            ENABLED="false"
          elif [ "${{ matrix.platform }}" == "windows" ] && [ "${{ needs.setup.outputs.build_windows }}" != "true" ]; then
            ENABLED="false"
          elif [ "${{ matrix.platform }}" == "macos" ] && [ "${{ needs.setup.outputs.build_macos }}" != "true" ]; then
            ENABLED="false"
          fi
          
          echo "enabled=$ENABLED" >> $GITHUB_OUTPUT
          echo "Platform ${{ matrix.platform }} enabled: $ENABLED"
      
      - name: Skip if disabled
        if: steps.check_enabled.outputs.enabled != 'true'
        shell: bash
        run: |
          echo "Skipping build for ${{ matrix.platform }} (disabled in configuration)"
          exit 0
      
      - name: Checkout code
        if: steps.check_enabled.outputs.enabled == 'true'
        uses: actions/checkout@v4
      
      - name: Set up Python
        if: steps.check_enabled.outputs.enabled == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: ${{ needs.setup.outputs.python_version }}
          cache: 'pip'
      
      - name: Install dependencies
        if: steps.check_enabled.outputs.enabled == 'true'
        shell: bash
        run: |
          python -m pip install --upgrade pip
          pip install nuitka ordered-set
          pip install -r requirements.txt || echo "No requirements.txt found"
          
          # Verify Nuitka installation
          echo "Nuitka version:"
          python -m nuitka --version
          
          # Check for C compiler (platform specific)
          if [ "${{ runner.os }}" == "Windows" ]; then
            echo "Checking for MSVC..."
            where cl 2>/dev/null || where gcc 2>/dev/null || echo "Warning: No compiler found, Nuitka will download MinGW"
          elif [ "${{ runner.os }}" == "macOS" ]; then
            echo "Checking for Clang..."
            clang --version || echo "Warning: Clang not found"
          else
            echo "Checking for GCC..."
            gcc --version || echo "Warning: GCC not found"
          fi
      
      - name: Discover Python modules
        if: steps.check_enabled.outputs.enabled == 'true'
        id: discover
        shell: bash
        run: |
          echo "Discovering Python modules in app/ directory..."
          echo "Current directory: $(pwd)"
          echo ""
          
          # Check if app directory exists
          if [ ! -d "app" ]; then
            echo "Error: app/ directory not found!"
            echo "Directory listing:"
            ls -la
            exit 1
          fi
          
          echo "Contents of app/ directory:"
          ls -la app/
          echo ""
          
          # Find all .py files in app/ (excluding __init__.py and test files)
          MODULES=$(find app -type f -name "*.py" ! -name "__init__.py" ! -name "test_*.py" ! -path "*/tests/*" ! -path "*/__pycache__/*" 2>/dev/null)
          
          if [ -z "$MODULES" ]; then
            echo "Error: No Python modules found in app/"
            echo ""
            echo "Full directory tree:"
            find app -type f -name "*.py" 2>/dev/null || echo "find command failed"
            exit 1
          fi
          
          echo "Found modules:"
          echo "$MODULES"
          echo ""
          
          # Count modules
          MODULE_COUNT=$(echo "$MODULES" | wc -l)
          echo "Total modules to compile: $MODULE_COUNT"
          echo ""
          
          # Save to file for next step
          echo "$MODULES" > modules_list.txt
          
          echo "Modules list saved to modules_list.txt"
          echo "Contents:"
          cat modules_list.txt
      
      - name: Generate API Documentation JSONs
        if: steps.check_enabled.outputs.enabled == 'true'
        shell: bash
        run: |
          echo "Generating API documentation files..."
          echo ""
          
          # Create Python script to analyze modules and generate JSONs
          cat > generate_api_docs.py << 'PYEOF'
          import ast
          import json
          import sys
          from pathlib import Path
          from typing import Dict, Any, List, Set
          
          # Force UTF-8 encoding
          if sys.platform == 'win32':
              import io
              sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
              sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
          
          
          class APIDocGenerator:
              """Generates API documentation JSONs from Python source files."""
              
              def __init__(self):
                  self.modules_data = {}  # {module_name: {cli: {}, rest: {}, licensed: {}}}
              
              def _get_type_annotation(self, annotation) -> str:
                  """Extract type from annotation node."""
                  if annotation is None:
                      return "Any"
                  
                  if isinstance(annotation, ast.Name):
                      return annotation.id
                  elif isinstance(annotation, ast.Constant):
                      return str(annotation.value)
                  elif isinstance(annotation, ast.Subscript):
                      # Handle List[str], Dict[str, int], etc.
                      value = self._get_type_annotation(annotation.value)
                      slice_val = self._get_type_annotation(annotation.slice)
                      return f"{value}[{slice_val}]"
                  elif isinstance(annotation, ast.Tuple):
                      # Handle Tuple types
                      elements = [self._get_type_annotation(e) for e in annotation.elts]
                      return f"Tuple[{', '.join(elements)}]"
                  elif isinstance(annotation, ast.Attribute):
                      # Handle module.Type annotations
                      return f"{annotation.attr}"
                  else:
                      return "Any"
              
              def _extract_function_params(self, func_node: ast.FunctionDef) -> Dict[str, str]:
                  """Extract function parameters with their types."""
                  params = {}
                  
                  for arg in func_node.args.args:
                      # Skip 'self' and 'cls'
                      if arg.arg in ('self', 'cls'):
                          continue
                      
                      param_type = self._get_type_annotation(arg.annotation)
                      params[arg.arg] = param_type
                  
                  return params
              
              def _check_nexus_decorator(self, class_body: List, func_index: int, decorator_names: List[str]) -> bool:
                  """
                  Check if the statement before a function is a NexusDecorators attribute access.
                  This handles the pattern:
                      NexusDecorators.allow_cli
                      def func1(self):
                  
                  Args:
                      class_body: List of nodes in the class body
                      func_index: Index of the function in class_body
                      decorator_names: List of decorator attribute names to match
                  """
                  if func_index == 0:
                      return False
                  
                  # Check the previous statement
                  prev_node = class_body[func_index - 1]
                  
                  # Check if it's an Expr containing an Attribute or Call
                  if isinstance(prev_node, ast.Expr):
                      # Pattern: NexusDecorators.allow_cli (simple attribute access)
                      if isinstance(prev_node.value, ast.Attribute):
                          if (hasattr(prev_node.value.value, 'id') and 
                              prev_node.value.value.id == 'NexusDecorators' and
                              prev_node.value.attr in decorator_names):
                              return True
                      
                      # Pattern: NexusDecorators.allow_license(...) (function call)
                      elif isinstance(prev_node.value, ast.Call):
                          if isinstance(prev_node.value.func, ast.Attribute):
                              if (hasattr(prev_node.value.func.value, 'id') and 
                                  prev_node.value.func.value.id == 'NexusDecorators' and
                                  prev_node.value.func.attr in decorator_names):
                                  return True
                  
                  return False
              
              def _is_cli_method(self, class_body: List, func_index: int, func_node: ast.FunctionDef) -> bool:
                  """Check if method has CLI decorator."""
                  # Check traditional @decorators
                  for decorator in func_node.decorator_list:
                      if isinstance(decorator, ast.Name):
                          if 'cli' in decorator.id.lower():
                              return True
                      elif isinstance(decorator, ast.Attribute):
                          if 'cli' in decorator.attr.lower():
                              return True
                      elif isinstance(decorator, ast.Call):
                          if isinstance(decorator.func, ast.Attribute):
                              if 'cli' in decorator.func.attr.lower():
                                  return True
                  
                  # Check NexusDecorators.allow_cli pattern
                  cli_decorators = ['allow_cli', 'allow_cli_license']
                  if self._check_nexus_decorator(class_body, func_index, cli_decorators):
                      return True
                  
                  return False
              
              def _is_rest_method(self, class_body: List, func_index: int, func_node: ast.FunctionDef) -> bool:
                  """Check if method has REST API decorator."""
                  rest_decorator_names = {
                      'route', 'get', 'post', 'put', 'delete', 'patch',
                      'app.route', 'api.route', 'restapi'
                  }
                  
                  # Check traditional @decorators
                  for decorator in func_node.decorator_list:
                      if isinstance(decorator, ast.Name):
                          if decorator.id in rest_decorator_names or 'rest' in decorator.id.lower():
                              return True
                      elif isinstance(decorator, ast.Attribute):
                          if decorator.attr in rest_decorator_names or 'rest' in decorator.attr.lower():
                              return True
                      elif isinstance(decorator, ast.Call):
                          if isinstance(decorator.func, ast.Attribute):
                              if decorator.func.attr in rest_decorator_names or 'rest' in decorator.func.attr.lower():
                                  return True
                  
                  # Check NexusDecorators.allow_restapi pattern
                  rest_nexus_decorators = ['allow_restapi', 'allow_restapi_license']
                  if self._check_nexus_decorator(class_body, func_index, rest_nexus_decorators):
                      return True
                  
                  return False
              
              def _is_licensed_method(self, class_body: List, func_index: int, func_node: ast.FunctionDef) -> bool:
                  """Check if method requires license."""
                  # Check traditional @decorators
                  for decorator in func_node.decorator_list:
                      if isinstance(decorator, ast.Name):
                          if 'license' in decorator.id.lower() or 'premium' in decorator.id.lower():
                              return True
                      elif isinstance(decorator, ast.Call):
                          if isinstance(decorator.func, ast.Name):
                              if 'license' in decorator.func.id.lower() or 'premium' in decorator.func.id.lower():
                                  return True
                  
                  # Check NexusDecorators with "license" in the name
                  license_nexus_decorators = ['allow_license', 'allow_cli_license', 'allow_restapi_license', 'require_license']
                  if self._check_nexus_decorator(class_body, func_index, license_nexus_decorators):
                      return True
                  
                  # Check docstring
                  docstring = ast.get_docstring(func_node)
                  if docstring:
                      doc_lower = docstring.lower()
                      if 'license' in doc_lower or 'premium' in doc_lower or 'paid' in doc_lower:
                          return True
                  
                  return False
              
              def _extract_class_info(self, class_node: ast.ClassDef) -> Dict[str, Any]:
                  """Extract methods and their parameters from a class."""
                  methods_info = {}
                  
                  for idx, node in enumerate(class_node.body):
                      if isinstance(node, ast.FunctionDef):
                          # Skip private methods (but allow __init__, __str__, etc.)
                          if node.name.startswith('_') and not node.name.startswith('__'):
                              continue
                          
                          params = self._extract_function_params(node)
                          
                          # Determine categories
                          is_cli = self._is_cli_method(class_node.body, idx, node)
                          is_rest = self._is_rest_method(class_node.body, idx, node)
                          is_licensed = self._is_licensed_method(class_node.body, idx, node)
                          
                          methods_info[node.name] = {
                              'params': params,
                              'is_cli': is_cli,
                              'is_rest': is_rest,
                              'is_licensed': is_licensed
                          }
                  
                  return methods_info
              
              def analyze_file(self, filepath: Path):
                  """Analyze a Python file and extract API information."""
                  try:
                      with open(filepath, 'r', encoding='utf-8') as f:
                          tree = ast.parse(f.read(), filename=str(filepath))
                  except Exception as e:
                      print(f"Warning: Could not parse {filepath}: {e}", file=sys.stderr)
                      return
                  
                  module_name = filepath.stem
                  
                  # Initialize module data structure
                  if module_name not in self.modules_data:
                      self.modules_data[module_name] = {
                          'cli': {},
                          'rest': {},
                          'licensed': {}
                      }
                  
                  # Process classes
                  for node in ast.walk(tree):
                      if isinstance(node, ast.ClassDef):
                          class_name = node.name
                          methods_info = self._extract_class_info(node)
                          
                          if not methods_info:
                              continue
                          
                          # Categorize methods
                          for method_name, info in methods_info.items():
                              params = info['params']
                              
                              # Add to CLI APIs
                              if info['is_cli']:
                                  if class_name not in self.modules_data[module_name]['cli']:
                                      self.modules_data[module_name]['cli'][class_name] = {}
                                  self.modules_data[module_name]['cli'][class_name][method_name] = params
                              
                              # Add to REST APIs
                              if info['is_rest']:
                                  if class_name not in self.modules_data[module_name]['rest']:
                                      self.modules_data[module_name]['rest'][class_name] = {}
                                  self.modules_data[module_name]['rest'][class_name][method_name] = params
                              
                              # Add to Licensed APIs
                              if info['is_licensed']:
                                  if class_name not in self.modules_data[module_name]['licensed']:
                                      self.modules_data[module_name]['licensed'][class_name] = {}
                                  self.modules_data[module_name]['licensed'][class_name][method_name] = params
                              
                              # If no decorator found, add public methods to CLI by default
                              if not (info['is_cli'] or info['is_rest'] or info['is_licensed']):
                                  if not method_name.startswith('_'):
                                      if class_name not in self.modules_data[module_name]['cli']:
                                          self.modules_data[module_name]['cli'][class_name] = {}
                                      self.modules_data[module_name]['cli'][class_name][method_name] = params
              
              def generate_json_files(self, output_dir: Path):
                  """Generate JSON files per module in the format: modulename.nexus.{cli|rest|licensed}"""
                  output_dir.mkdir(exist_ok=True)
                  
                  total_files = 0
                  total_cli = 0
                  total_rest = 0
                  total_licensed = 0
                  
                  for module_name, module_data in self.modules_data.items():
                      # Generate modulename.nexus.cli
                      cli_path = output_dir / f'{module_name}.nexus.cli'
                      with open(cli_path, 'w', encoding='utf-8') as f:
                          json.dump(module_data['cli'], f, indent=2, ensure_ascii=False)
                      cli_count = sum(len(methods) for methods in module_data['cli'].values())
                      print(f"✓ Generated: {cli_path} ({len(module_data['cli'])} classes, {cli_count} methods)")
                      total_cli += cli_count
                      total_files += 1
                      
                      # Generate modulename.nexus.rest
                      rest_path = output_dir / f'{module_name}.nexus.rest'
                      with open(rest_path, 'w', encoding='utf-8') as f:
                          json.dump(module_data['rest'], f, indent=2, ensure_ascii=False)
                      rest_count = sum(len(methods) for methods in module_data['rest'].values())
                      print(f"✓ Generated: {rest_path} ({len(module_data['rest'])} classes, {rest_count} methods)")
                      total_rest += rest_count
                      total_files += 1
                      
                      # Generate modulename.nexus.licensed
                      licensed_path = output_dir / f'{module_name}.nexus.licensed'
                      with open(licensed_path, 'w', encoding='utf-8') as f:
                          json.dump(module_data['licensed'], f, indent=2, ensure_ascii=False)
                      licensed_count = sum(len(methods) for methods in module_data['licensed'].values())
                      print(f"✓ Generated: {licensed_path} ({len(module_data['licensed'])} classes, {licensed_count} methods)")
                      total_licensed += licensed_count
                      total_files += 1
                      
                      print("")
                  
                  return total_files, total_cli, total_rest, total_licensed
          
          
          def main():
              # Read modules list
              with open('modules_list.txt', 'r') as f:
                  modules = [line.strip() for line in f if line.strip()]
              
              print("Analyzing modules for API documentation...")
              print("")
              
              generator = APIDocGenerator()
              
              # Analyze each module
              for module_path in modules:
                  print(f"Processing: {module_path}")
                  generator.analyze_file(Path(module_path))
              
              print("")
              print("Generating JSON files...")
              print("")
              
              # Generate JSON files in bin directory
              output_dir = Path('./bin')
              total_files, total_cli, total_rest, total_licensed = generator.generate_json_files(output_dir)
              
              print("========================================")
              print("Summary:")
              print(f"  Total files generated: {total_files}")
              print(f"  Modules processed: {len(generator.modules_data)}")
              print(f"  Total CLI methods: {total_cli}")
              print(f"  Total REST methods: {total_rest}")
              print(f"  Total Licensed methods: {total_licensed}")
              print("========================================")
          
          
          if __name__ == '__main__':
              main()
          PYEOF
          
          # Run the API documentation generator
          export PYTHONIOENCODING=utf-8
          python generate_api_docs.py
          
          echo ""
          echo "=========================================="
          echo "API Documentation Files Created"
          echo "=========================================="
          
          # Display file listing
          if [ -d "./bin" ]; then
            echo ""
            echo "Generated files:"
            ls -lh ./bin/*.nexus.* 2>/dev/null || echo "No .nexus.* files found"
            echo ""
          fi
          
          echo "[OK] API documentation generation complete"

      - name: Analyze imports and create minimal requirements
        if: steps.check_enabled.outputs.enabled == 'true'
        shell: bash
        run: |
          echo "Analyzing imports from Python modules..."
          echo ""
          
          # Get Python version
          PYTHON_VERSION="${{ needs.setup.outputs.python_version }}"
          echo "Target Python version: $PYTHON_VERSION"
          echo ""
          
          # Create a Python script to extract imports
          cat > analyze_imports.py << 'PYEOF'
          import ast
          import sys
          import json
          import re
          from pathlib import Path
          
          # Force UTF-8 encoding for stdout
          if sys.platform == 'win32':
              import io
              sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
              sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
          
          # Standard library modules (don't include these)
          STDLIB_MODULES = {
              'abc', 'aifc', 'argparse', 'array', 'ast', 'asynchat', 'asyncio', 'asyncore',
              'atexit', 'audioop', 'base64', 'bdb', 'binascii', 'binhex', 'bisect', 'builtins',
              'bz2', 'calendar', 'cgi', 'cgitb', 'chunk', 'cmath', 'cmd', 'code', 'codecs',
              'codeop', 'collections', 'colorsys', 'compileall', 'concurrent', 'configparser',
              'contextlib', 'contextvars', 'copy', 'copyreg', 'cProfile', 'crypt', 'csv',
              'ctypes', 'curses', 'dataclasses', 'datetime', 'dbm', 'decimal', 'difflib',
              'dis', 'distutils', 'doctest', 'email', 'encodings', 'enum', 'errno', 'faulthandler',
              'fcntl', 'filecmp', 'fileinput', 'fnmatch', 'formatter', 'fractions', 'ftplib',
              'functools', 'gc', 'getopt', 'getpass', 'gettext', 'glob', 'graphlib', 'grp',
              'gzip', 'hashlib', 'heapq', 'hmac', 'html', 'http', 'imaplib', 'imghdr', 'imp',
              'importlib', 'inspect', 'io', 'ipaddress', 'itertools', 'json', 'keyword',
              'lib2to3', 'linecache', 'locale', 'logging', 'lzma', 'mailbox', 'mailcap',
              'marshal', 'math', 'mimetypes', 'mmap', 'modulefinder', 'msilib', 'msvcrt',
              'multiprocessing', 'netrc', 'nis', 'nntplib', 'numbers', 'operator', 'optparse',
              'os', 'ossaudiodev', 'parser', 'pathlib', 'pdb', 'pickle', 'pickletools', 'pipes',
              'pkgutil', 'platform', 'plistlib', 'poplib', 'posix', 'posixpath', 'pprint',
              'profile', 'pstats', 'pty', 'pwd', 'py_compile', 'pyclbr', 'pydoc', 'queue',
              'quopri', 'random', 're', 'readline', 'reprlib', 'resource', 'rlcompleter',
              'runpy', 'sched', 'secrets', 'select', 'selectors', 'shelve', 'shlex', 'shutil',
              'signal', 'site', 'smtpd', 'smtplib', 'sndhdr', 'socket', 'socketserver', 'spwd',
              'sqlite3', 'ssl', 'stat', 'statistics', 'string', 'stringprep', 'struct',
              'subprocess', 'sunau', 'symbol', 'symtable', 'sys', 'sysconfig', 'syslog',
              'tabnanny', 'tarfile', 'telnetlib', 'tempfile', 'termios', 'test', 'textwrap',
              'threading', 'time', 'timeit', 'tkinter', 'token', 'tokenize', 'trace', 'traceback',
              'tracemalloc', 'tty', 'turtle', 'turtledemo', 'types', 'typing', 'unicodedata',
              'unittest', 'urllib', 'uu', 'uuid', 'venv', 'warnings', 'wave', 'weakref',
              'webbrowser', 'winreg', 'winsound', 'wsgiref', 'xdrlib', 'xml', 'xmlrpc', 'zipapp',
              'zipfile', 'zipimport', 'zlib', '_thread'
          }
          
          def get_imports_from_file(filepath):
              """Extract import statements from a Python file."""
              imports = set()
              try:
                  with open(filepath, 'r', encoding='utf-8') as f:
                      tree = ast.parse(f.read(), filename=str(filepath))
                  
                  for node in ast.walk(tree):
                      if isinstance(node, ast.Import):
                          for alias in node.names:
                              module = alias.name.split('.')[0]
                              imports.add(module)
                      elif isinstance(node, ast.ImportFrom):
                          if node.module:
                              module = node.module.split('.')[0]
                              imports.add(module)
              except Exception as e:
                  print(f"Warning: Could not parse {filepath}: {e}", file=sys.stderr)
              
              return imports
          
          def main():
              python_version = sys.argv[1] if len(sys.argv) > 1 else "3.11"
              
              # Read modules list
              with open('modules_list.txt', 'r') as f:
                  modules = [line.strip() for line in f if line.strip()]
              
              # Track imports per module
              module_imports = {}
              all_imports = set()
              
              print("Scanning files for imports...")
              for module_path in modules:
                  print(f"  - {module_path}")
                  imports = get_imports_from_file(module_path)
                  module_name = Path(module_path).stem
                  
                  # Filter external imports
                  external_imports = {
                      imp for imp in imports 
                      if imp not in STDLIB_MODULES and not imp.startswith('app')
                  }
                  
                  module_imports[module_name] = sorted(external_imports)
                  all_imports.update(external_imports)
              
              print(f"\nFound {len(all_imports)} unique external dependencies")
              
              # Load existing requirements.txt to get versions
              requirements_map = {}
              if Path('requirements.txt').exists():
                  print("\nReading requirements.txt for version information...")
                  with open('requirements.txt', 'r') as f:
                      for line in f:
                          line = line.strip()
                          # Skip comments and empty lines
                          if not line or line.startswith('#'):
                              continue
                          
                          # Parse requirement line
                          match = re.match(r'^([a-zA-Z0-9_-]+)(\[.*?\])?(.*?)', line)
                          if match:
                              package_name = match.group(1).lower()
                              version_spec = (match.group(2) or '') + (match.group(3) or '')
                              requirements_map[package_name] = line.strip()
                              print(f"  Found: {package_name} -> {line}")
              
              # Save per-module requirements with versions (NEW FORMAT: modulename.nexus.requirements)
              print("\nGenerating per-module requirements:")
              
              for module_name, imports in module_imports.items():
                  if imports:
                      # NEW: Use .nexus.requirements format
                      req_file = Path('./bin') / f"{module_name}.nexus.requirements"
                      req_file.parent.mkdir(exist_ok=True)
                      
                      print(f"  {module_name}:")
                      with open(req_file, 'w', encoding='utf-8') as f:
                          for imp in imports:
                              # Try to find version from requirements_map
                              imp_lower = imp.lower()
                              if imp_lower in requirements_map:
                                  req_line = requirements_map[imp_lower]
                                  f.write(f"{req_line}\n")
                                  print(f"    [OK] {req_line}")
                              else:
                                  # Package not in requirements.txt
                                  f.write(f"{imp}\n")
                                  print(f"    [+] {imp} (no version)")
                  else:
                      print(f"  {module_name}: (no external dependencies)")
              
              # Save module dependencies mapping (NEW FORMAT: modulename.nexus.dependencies)
              print("\nGenerating module dependencies files...")
              for module_name, imports in module_imports.items():
                  dep_file = Path('./bin') / f"{module_name}.nexus.dependencies"
                  with open(dep_file, 'w', encoding='utf-8') as f:
                      json.dump(sorted(imports), f, indent=2)
                  print(f"  ✓ {dep_file}")
              
              print(f"\nSaved:")
              print(f"  - Per-module requirements: *.nexus.requirements")
              print(f"  - Module dependencies: *.nexus.dependencies")
          
          if __name__ == '__main__':
              main()
          PYEOF
          
          # Run the analysis
          export PYTHONIOENCODING=utf-8
          python analyze_imports.py "$PYTHON_VERSION"
          
          echo ""
          echo "[OK] Requirements analysis complete"
      

      - name: Build all modules with Nuitka
        if: steps.check_enabled.outputs.enabled == 'true'
        shell: bash
        run: |
          # Create bin directory
          mkdir -p ./bin
          
          EXTENSION="${{ matrix.extension }}"
          PLATFORM="${{ matrix.platform }}"
          PYTHON_VERSION="${{ needs.setup.outputs.python_version }}"
          
          echo "Building all modules for $PLATFORM..."
          echo "Extension: $EXTENSION"
          echo "Working directory: $(pwd)"
          echo "Python version: $(python --version)"
          echo ""
          
          # Get Python executable path
          PYTHON_EXEC=$(which python)
          echo "Python executable: $PYTHON_EXEC"
          
          # Verify Nuitka installation
          echo "Verifying Nuitka..."
          $PYTHON_EXEC -m nuitka --version
          
          # Check if modules_list.txt exists
          if [ ! -f "modules_list.txt" ]; then
            echo "Error: modules_list.txt not found!"
            exit 1
          fi
          
          echo "Modules to compile:"
          cat modules_list.txt
          echo ""
          
          # Read modules list and compile
          SUCCESS_COUNT=0
          FAIL_COUNT=0
          
          while IFS= read -r MODULE_PATH; do
            # Skip empty lines
            [ -z "$MODULE_PATH" ] && continue
            
            # Get module name without extension and path
            MODULE_NAME=$(basename "$MODULE_PATH" .py)
            
            echo ""
            echo "=========================================="
            echo "Building: $MODULE_NAME"
            echo "Source: $MODULE_PATH"
            echo "=========================================="
            
            # Check if source file exists
            if [ ! -f "$MODULE_PATH" ]; then
              echo "Error: Source file not found: $MODULE_PATH"
              echo "Current directory contents:"
              ls -la
              echo ""
              echo "App directory contents:"
              ls -la app/ 2>/dev/null || echo "app/ directory not found"
              FAIL_COUNT=$((FAIL_COUNT + 1))
              continue
            fi
            
            # Build with Nuitka using explicit Python executable and -m flag
            echo "Running Nuitka with Python $PYTHON_VERSION..."
            $PYTHON_EXEC -m nuitka \
              --module \
              --output-dir=./bin \
              --include-package=app \
              --follow-import-to=app \
              --nofollow-imports \
              --assume-yes-for-downloads \
              --no-pyi-file \
              --show-progress \
              "$MODULE_PATH"
            
            NUITKA_EXIT=$?
            
            if [ $NUITKA_EXIT -eq 0 ]; then
              # Check what files were created
              echo ""
              echo "Checking for compiled output..."
              
              # Nuitka creates files like: ModuleName.cpython-311-x86_64-linux-gnu.so
              # or: ModuleName.pyd on Windows
              
              FOUND_FILES=$(find ./bin -name "${MODULE_NAME}*${EXTENSION}" -o -name "${MODULE_NAME}.cpython*${EXTENSION}" 2>/dev/null)
              
              if [ -n "$FOUND_FILES" ]; then
                echo "[OK] Successfully built:"
                echo "$FOUND_FILES" | while read f; do echo "  - $f"; done
                SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
              else
                echo "[ERROR] Nuitka succeeded but no output file found"
                echo "Expected pattern: ${MODULE_NAME}*${EXTENSION}"
                echo "Bin directory contents:"
                ls -la ./bin/
                FAIL_COUNT=$((FAIL_COUNT + 1))
              fi
            else
              echo "[ERROR] Nuitka failed with exit code: $NUITKA_EXIT"
              FAIL_COUNT=$((FAIL_COUNT + 1))
            fi
            
          done < modules_list.txt
          
          echo ""
          echo "=========================================="
          echo "Build Summary"
          echo "=========================================="
          echo "Total modules: $((SUCCESS_COUNT + FAIL_COUNT))"
          echo "Successfully built: $SUCCESS_COUNT"
          echo "Failed: $FAIL_COUNT"
          
          # List all files in bin directory
          echo ""
          echo "Final bin directory contents:"
          find ./bin -type f -ls 2>/dev/null || ls -laR ./bin/ 2>/dev/null || echo "Bin directory is empty"
          
          # Fail if no modules were built
          if [ "$SUCCESS_COUNT" -eq 0 ]; then
            echo ""
            echo "ERROR: No modules were successfully compiled!"
            echo "This might be due to:"
            echo "  1. Missing C compiler"
            echo "  2. Syntax errors in Python files"
            echo "  3. Missing dependencies"
            echo "  4. Nuitka compatibility issues"
            echo "  5. Incorrect file paths in modules_list.txt"
            exit 1
          fi
      
      - name: Verify binaries
        if: steps.check_enabled.outputs.enabled == 'true'
        shell: bash
        run: |
          echo "Contents of bin directory:"
          ls -lah ./bin/ 2>/dev/null || echo "No bin directory"
          
          echo ""
          echo "Searching for compiled modules..."
          
          # Count compiled modules
          if [ "${{ matrix.platform }}" == "windows" ]; then
            MODULE_COUNT=$(find ./bin -name "*.pyd" 2>/dev/null | wc -l)
            echo "Found .pyd files:"
            find ./bin -name "*.pyd" 2>/dev/null
          else
            MODULE_COUNT=$(find ./bin -name "*.so" 2>/dev/null | wc -l)
            echo "Found .so files:"
            find ./bin -name "*.so" 2>/dev/null
          fi
          
          echo ""
          echo "Total compiled modules: $MODULE_COUNT"
          
          if [ "$MODULE_COUNT" -eq 0 ]; then
            echo "Error: No compiled modules found!"
            echo ""
            echo "Complete bin directory structure:"
            find ./bin -type f 2>/dev/null || echo "Bin directory is empty"
            exit 1
          fi
          
          echo "[OK] Verification passed: $MODULE_COUNT modules compiled"

      - name: Create platform-specific zip
        if: steps.check_enabled.outputs.enabled == 'true'
        shell: bash
        run: |
          BINARY_BASE="${{ needs.setup.outputs.binary_name }}"
          PLATFORM="${{ matrix.platform }}"
          VERSION="${{ needs.version.outputs.new_version }}"
          
          # Create zip filename
          ZIP_NAME="${BINARY_BASE}-${PLATFORM}-modules.zip"
          
          echo "Creating zip file: $ZIP_NAME"
          
          # Check if bin directory has files
          FILE_COUNT=$(find ./bin -type f 2>/dev/null | wc -l)
          echo "Files in bin directory: $FILE_COUNT"
          
          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "Error: No files to zip in ./bin directory"
            ls -la ./bin/ 2>/dev/null || echo "Bin directory doesn't exist"
            exit 1
          fi
          
          # Copy README.md from root to bin directory
          if [ -f "README.md" ]; then
            echo "Copying README.md from root to package..."
            cp README.md ./bin/
            echo "[OK] README.md copied"
          else
            echo "Warning: README.md not found in root directory"
          fi
          
          # List files that will be zipped
          echo ""
          echo "Files to be zipped:"
          ls -lh ./bin/
          
          # Create zip from bin directory
          if [ "${{ runner.os }}" == "Windows" ]; then
            # Use PowerShell on Windows
            cd ./bin
            powershell -Command "Compress-Archive -Path * -DestinationPath '../$ZIP_NAME' -Force"
            cd ..
          else
            # Use zip on Unix
            cd ./bin
            zip -r "../$ZIP_NAME" * || {
              echo "Zip failed, trying tar.gz..."
              tar -czf "../${BINARY_BASE}-${PLATFORM}-modules.tar.gz" *
              cd ..
              echo "Created tar.gz instead: ${BINARY_BASE}-${PLATFORM}-modules.tar.gz"
              
              # Verify tar.gz was created
              if [ -f "${BINARY_BASE}-${PLATFORM}-modules.tar.gz" ]; then
                echo "[OK] Successfully created tar.gz"
                ls -lh "${BINARY_BASE}-${PLATFORM}-modules.tar.gz"
                echo "zip_name=${BINARY_BASE}-${PLATFORM}-modules.tar.gz" >> $GITHUB_OUTPUT
              else
                echo "Error: Failed to create archive"
                exit 1
              fi
              exit 0
            }
            cd ..
          fi
          
          # Verify the zip/archive was created
          if [ -f "$ZIP_NAME" ]; then
            echo "[OK] Created: $ZIP_NAME"
            ls -lh "$ZIP_NAME"
            
            # Verify zip contents
            echo ""
            echo "Archive contents:"
            if [ "${{ runner.os }}" == "Windows" ]; then
              powershell -Command "Add-Type -Assembly System.IO.Compression.FileSystem; [System.IO.Compression.ZipFile]::OpenRead('$ZIP_NAME').Entries | Select-Object FullName, Length | Format-Table"
            else
              unzip -l "$ZIP_NAME" 2>/dev/null || zipinfo "$ZIP_NAME" 2>/dev/null || echo "Cannot list zip contents (not critical)"
            fi
            
            # Save zip name for upload
            echo "zip_name=$ZIP_NAME" >> $GITHUB_OUTPUT
          else
            echo "Error: Archive file not created: $ZIP_NAME"
            echo "Current directory contents:"
            ls -la
            exit 1
          fi
        id: create_zip
      
      - name: Upload binary artifact
        if: steps.check_enabled.outputs.enabled == 'true' && github.event_name != 'pull_request'
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.artifact_name }}
          path: |
            ./*-modules.zip
            ./*-modules.tar.gz
          retention-days: 5
        continue-on-error: true

  release:
      name: Create Release
      needs: [setup, version, build]
      runs-on: ubuntu-latest
      permissions:
        contents: write
      
      steps:
        - name: Checkout code
          uses: actions/checkout@v4
          with:
            fetch-depth: 0
            token: ${{ secrets.GITHUB_TOKEN }}
        
        - name: Download all artifacts
          uses: actions/download-artifact@v4
          with:
            path: ./artifacts
        
        - name: List artifacts
          run: |
            echo "Downloaded artifacts:"
            ls -R ./artifacts || echo "No artifacts found"
        
        - name: Prepare release files
          run: |
            mkdir -p ./release
            
            # Copy all zip files to release directory
            echo "Copying module packages..."
            find ./artifacts -name "*-modules.zip" -exec cp {} ./release/ \; || echo "No zip packages found"
            find ./artifacts -name "*-modules.tar.gz" -exec cp {} ./release/ \; || echo "No tar.gz packages found"
            
            echo "Release files:"
            ls -lah ./release

        - name: Generate release notes
          run: |
            VERSION="${{ needs.version.outputs.new_version }}"
            BUMP_TYPE="${{ needs.version.outputs.version_bump }}"
            COMPONENT="${{ needs.setup.outputs.component_name }}"
            BINARY_NAME="${{ needs.setup.outputs.binary_name }}"
            PYTHON_VERSION="${{ needs.setup.outputs.python_version }}"
            REPO="${{ github.repository }}"
            
            # Build list of available module packages
            PACKAGES=""
            if [ "${{ needs.setup.outputs.build_linux }}" == "true" ]; then
              PACKAGES="${PACKAGES}- **Linux Modules (.so files)**: \`${BINARY_NAME}-linux-modules.zip\`"$'\n'
            fi
            if [ "${{ needs.setup.outputs.build_windows }}" == "true" ]; then
              PACKAGES="${PACKAGES}- **Windows Modules (.pyd files)**: \`${BINARY_NAME}-windows-modules.zip\`"$'\n'
            fi
            if [ "${{ needs.setup.outputs.build_macos }}" == "true" ]; then
              PACKAGES="${PACKAGES}- **macOS Modules (.so files)**: \`${BINARY_NAME}-macos-modules.zip\`"$'\n'
            fi

            # Create the main file template
            cat > release_notes.md << 'MDEOF'
            ## VERSION_PLACEHOLDER
            
            ### Release Information
            - **Component**: COMPONENT_PLACEHOLDER
            - **Binary Name**: BINARY_NAME_PLACEHOLDER
            - **Python Version**: PYTHON_VERSION_PLACEHOLDER
            - **Release Type**: BUMP_TYPE_PLACEHOLDER
            
            ### Changes
            MDEOF
            
            # Add commit messages
            LAST_TAG=$(git describe --tags --abbrev=0 2>/dev/null || echo "")
            if [ -n "$LAST_TAG" ]; then
              git log ${LAST_TAG}..HEAD --pretty=format:"- %s" >> release_notes.md
            else
              echo "- Initial release" >> release_notes.md
            fi
            
            cat >> release_notes.md << 'MDEOF'
            
            ### Available Module Packages
            PACKAGES_PLACEHOLDER
            
            ### What's Included
            Each platform-specific zip file contains **compiled Python modules** (binary extensions) with metadata:
            
            **Binary Files:**
            - **Linux/macOS**: `.so` files (Python extension modules)
            - **Windows**: `.pyd` files (Python extension modules)
            
            **Metadata Files (NEW):**
            - `modulename.nexus.cli` - CLI API documentation (JSON)
            - `modulename.nexus.rest` - REST API documentation (JSON)
            - `modulename.nexus.licensed` - Licensed features documentation (JSON)
            - `modulename.nexus.requirements` - Module-specific requirements
            - `modulename.nexus.dependencies` - Module dependencies mapping (JSON)
            - `modulename.nexus.md` - Module documentation (Markdown)
            
            **Utilities:**
            - `NexusLoader.py` - Dynamic module loader
            - `NexusLoader.nexus.md` - Loader documentation
            - `README.md` - Project documentation
            
            **Benefits:**
            - Source code protected (IP protection)
            - No .py files included
            - Native performance
            - Direct Python import capability
            - Complete API documentation included
            - Per-module dependency tracking
            
            **Important:**
            - Modules are platform-specific (not cross-compatible)
            - Requires Python PYTHON_VERSION_PLACEHOLDER
            - Binary extensions only (no source code)
            
            ### Installation
            
            #### Prerequisites
            Check the `.nexus.requirements` files for each module's specific dependencies.
            
            #### Option 1: Automatic with NexusSkyBase (Recommended)
            ```python
            from app.Lib.NexusSkyBase import NexusSkyBase
            
            # From GitHub release
            nexus = NexusSkyBase.from_github(
                repo_url='https://github.com/REPO_PLACEHOLDER',
                version='VERSION_PLACEHOLDER',
                release_name_template='BINARY_NAME_PLACEHOLDER'
            )
            
            # From direct URL
            nexus = NexusSkyBase.from_url(
                'https://github.com/REPO_PLACEHOLDER/releases/download/VERSION_PLACEHOLDER/BINARY_NAME_PLACEHOLDER-linux-modules.zip'
            )
            
            # From local path
            nexus = NexusSkyBase.from_path('./BINARY_NAME_PLACEHOLDER-linux-modules.zip')
            
            # Use loaded modules
            MyClass = nexus.MyClass
            result = nexus.some_function()
            ```
            
            #### Option 2: Manual Installation
            
            **Linux/macOS:**
            ```bash
            wget https://github.com/REPO_PLACEHOLDER/releases/download/VERSION_PLACEHOLDER/BINARY_NAME_PLACEHOLDER-linux-modules.zip
            unzip BINARY_NAME_PLACEHOLDER-linux-modules.zip -d ~/.nexus/bin/
            
            # Install module-specific dependencies
            pip install -r ~/.nexus/bin/modulename.nexus.requirements
            ```
            
            **Windows:**
            ```powershell
            # Download and extract BINARY_NAME_PLACEHOLDER-windows-modules.zip
            # Add to Python path
            import sys
            sys.path.insert(0, 'C:\\Users\\YourName\\.nexus\\bin')
            
            # Install dependencies for specific module
            pip install -r C:\Users\YourName\.nexus\bin\modulename.nexus.requirements
            
            import YourModule
            ```
            
            ### Usage Example
            
            ```python
            from YourModule import YourClass
            instance = YourClass()
            result = instance.do_something()
            ```
            
            ### Exploring Module APIs
            
            Each module includes comprehensive API documentation:
            
            ```python
            import json
            from pathlib import Path
            
            # Load CLI API documentation
            with open('modulename.nexus.cli') as f:
                cli_apis = json.load(f)
                print(f"Available CLI methods: {cli_apis}")
            
            # Load REST API documentation
            with open('modulename.nexus.rest') as f:
                rest_apis = json.load(f)
                print(f"Available REST endpoints: {rest_apis}")
            
            # Check module dependencies
            with open('modulename.nexus.dependencies') as f:
                deps = json.load(f)
                print(f"Required packages: {deps}")
            ```
            
            ### Platform Compatibility
            | Platform | File Type | Python Version |
            |----------|-----------|----------------|
            | Linux x64 | .so | PYTHON_VERSION_PLACEHOLDER |
            | Windows | .pyd | PYTHON_VERSION_PLACEHOLDER |
            | macOS | .so | PYTHON_VERSION_PLACEHOLDER |
            
            ### File Naming Convention
            All metadata files follow the pattern: `modulename.nexus.{extension}`
            - `.nexus.cli` - CLI API definitions
            - `.nexus.rest` - REST API definitions
            - `.nexus.licensed` - Licensed features
            - `.nexus.requirements` - Dependencies list
            - `.nexus.dependencies` - Dependency mapping (JSON)
            - `.nexus.md` - Documentation
            
            ---
            
            Need help? Check the repository documentation or open an issue.
            
            Built with love by the Nexus Team
            MDEOF
            
            # Replace placeholders (single line safe)
            sed -i "s|VERSION_PLACEHOLDER|${VERSION}|g" release_notes.md
            sed -i "s|COMPONENT_PLACEHOLDER|${COMPONENT}|g" release_notes.md
            sed -i "s|BINARY_NAME_PLACEHOLDER|${BINARY_NAME}|g" release_notes.md
            sed -i "s|PYTHON_VERSION_PLACEHOLDER|${PYTHON_VERSION}|g" release_notes.md
            sed -i "s|BUMP_TYPE_PLACEHOLDER|${BUMP_TYPE}|g" release_notes.md
            sed -i "s|REPO_PLACEHOLDER|${REPO}|g" release_notes.md
            
            # Insert PACKAGES safely without sed
            awk -v text="${PACKAGES}" '/PACKAGES_PLACEHOLDER/{print text; next}1' release_notes.md > tmp && mv tmp release_notes.md
            
            echo "✓ Release notes created successfully:"
            echo "-------------------------------------"
            cat release_notes.md
        
        - name: Create Git tag
          run: |
            VERSION="${{ needs.version.outputs.new_version }}"
            COMPONENT="${{ needs.setup.outputs.component_name }}"
            
            git config user.name "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            
            # Check if tag already exists
            if git rev-parse "$VERSION" >/dev/null 2>&1; then
              echo "Tag $VERSION already exists, skipping tag creation"
            else
              git tag -a "$VERSION" -m "Release $VERSION for component $COMPONENT"
              git push origin "$VERSION"
            fi
        
        - name: Create GitHub Release
          uses: softprops/action-gh-release@v1
          with:
            tag_name: ${{ needs.version.outputs.new_version }}
            name: ${{ needs.version.outputs.new_version }}
            body_path: release_notes.md
            files: ./release/*
            draft: false
            prerelease: false
          env:
            GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        
        - name: Update version files
          run: |
            VERSION="${{ needs.version.outputs.new_version }}"
            COMPONENT="${{ needs.setup.outputs.component_name }}"
            
            # Create versions directory
            mkdir -p .versions
            
            # Update component version file
            echo "$VERSION" > ".versions/${COMPONENT}_VERSION"
            
            # Update main VERSION file
            echo "$VERSION" > VERSION
            
            # Commit and push
            git config user.name "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            git add .versions/ VERSION
            git commit -m "chore: bump ${COMPONENT} version to $VERSION [skip ci]" || echo "No changes to commit"
            git push origin main || echo "No changes to push"

  notify:
    name: Send Notification
    needs: [setup, version, release]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - name: Check job status
        run: |
          if [ "${{ needs.release.result }}" == "success" ]; then
            echo "BUILD_STATUS=SUCCESS" >> $GITHUB_ENV
            echo "BUILD_COLOR=good" >> $GITHUB_ENV
          else
            echo "BUILD_STATUS=FAILED" >> $GITHUB_ENV
            echo "BUILD_COLOR=danger" >> $GITHUB_ENV
          fi
      
      - name: Send notification
        run: |
          COMPONENT="${{ needs.setup.outputs.component_name }}"
          VERSION="${{ needs.version.outputs.new_version }}"
          
          echo "=========================================="
          echo "Release ${COMPONENT} ${VERSION}: ${{ env.BUILD_STATUS }}"
          echo "=========================================="